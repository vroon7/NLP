{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vroon7/NLP/blob/main/Assignment2.py\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20992584",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20992584",
        "outputId": "98cdacef-2ee4-4a3c-ade0-939a42caf6b5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to\n",
            "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Necessary library imports\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import string\n",
        "from nltk.parse.stanford import StanfordDependencyParser\n",
        "#from nltk import word_tokenize\n",
        "import spacy\n",
        "import re\n",
        "from nltk.corpus import wordnet as wn\n",
        "from spacy import displacy\n",
        "from collections import Counter\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6047ebc",
      "metadata": {
        "id": "a6047ebc"
      },
      "outputs": [],
      "source": [
        "# Load the dataset and preprocess it\n",
        "Sentence = np.array(pd.read_csv('it-corpus.tsv', sep = '\\t').Sentence)\n",
        "Sentence = np.unique(Sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8de8da3",
      "metadata": {
        "id": "a8de8da3"
      },
      "outputs": [],
      "source": [
        "Feature1 = []\n",
        "Feature2 = []\n",
        "Feature3 = []\n",
        "Feature4 = []\n",
        "Feature5 = []\n",
        "Feature6 = []\n",
        "Feature7 = []\n",
        "Feature7_1 = []\n",
        "Feature7_2 = []\n",
        "Feature7_3 = []\n",
        "Feature7_4 = []\n",
        "Feature7_5 = []\n",
        "Feature7_6 = []\n",
        "Feature7_7 = []\n",
        "Feature7_8 = []\n",
        "Feature8 = []\n",
        "Feature9 = []\n",
        "Feature10 = []\n",
        "Feature11 = []\n",
        "Feature12 = []\n",
        "Feature13 = []\n",
        "Feature14 = []\n",
        "Feature15 = []\n",
        "Feature16 = []\n",
        "Feature18 = []\n",
        "Feature19 = []\n",
        "Feature20 = []\n",
        "list_of_sentence = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8d0745f",
      "metadata": {
        "id": "e8d0745f"
      },
      "outputs": [],
      "source": [
        "def check_noun_phrase(noun_phrase_tree, total_counts = 0):\n",
        "    flag=1\n",
        "    for current_tree in noun_phrase_tree:\n",
        "        if type(current_tree) == nltk.tree.Tree and current_tree.label() == 'NP':\n",
        "            flag=0\n",
        "\n",
        "    if noun_phrase_tree.label() == 'NP' and flag==1:\n",
        "        total_counts += 1\n",
        "    next_recurrsion = 0\n",
        "    for current_tree in noun_phrase_tree:\n",
        "        if type(current_tree) == nltk.tree.Tree:\n",
        "            next_recurrsion = check_noun_phrase(current_tree, total_counts)\n",
        "    return max(total_counts, next_recurrsion)\n",
        "\n",
        "def for_many(check_pos, pos_tagging):\n",
        "    temp_flag = False\n",
        "    for i in pos_tagging:\n",
        "        if(i[1]==check_pos):\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "def for_verb(pos_tagging):\n",
        "    temp_flag = False\n",
        "    for i in pos_tagging:\n",
        "        if(i[1][:2]=='VB'):\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "def for_Feature7(current_index, pos_tagging):\n",
        "    answer_list = []\n",
        "    if(current_index - 4 >= 0):\n",
        "        for i in range(current_index - 4, current_index):\n",
        "            answer_list.append(pos_tagging[i][1])\n",
        "    else:\n",
        "        for i in range(0, 4 - current_index):\n",
        "            answer_list.append('ABS')\n",
        "        for i in range(0, current_index):\n",
        "            answer_list.append(pos_tagging[i][1])\n",
        "\n",
        "    if((len(pos_tagging) - 1 - current_index) >= 4):\n",
        "        for i in range(current_index + 1, current_index + 5):\n",
        "            answer_list.append(pos_tagging[i][1])\n",
        "    else:\n",
        "        for i in range(current_index + 1, len(pos_tagging)):\n",
        "            answer_list.append(pos_tagging[i][1])\n",
        "        for i in range(0, 4 - (len(pos_tagging) - 1 - current_index)):\n",
        "            answer_list.append('ABS')\n",
        "    return answer_list\n",
        "\n",
        "def for_NP_and_adjective(np_adj_tree):\n",
        "    first_condition = False\n",
        "    second_condition = False\n",
        "    recurrsion = False\n",
        "    if(np_adj_tree.label() == 'NP'):\n",
        "        first_condition = True\n",
        "\n",
        "    for current_tree in np_adj_tree:\n",
        "        if(type(current_tree) == nltk.tree.Tree):\n",
        "            recurrsion = for_NP_and_adjective(current_tree)\n",
        "        else:\n",
        "            if(current_tree[1] == 'JJ'):\n",
        "                second_condition = True\n",
        "\n",
        "    return ((first_condition and second_condition) or recurrsion)\n",
        "\n",
        "def wordnet_for_last_two(current_index, pos_tagging, n, current_type):\n",
        "    if((current_index < n - 1) and pos_tagging[current_index + 1][1][:2] == 'VB'):\n",
        "        for element in wn.synsets(pos_tagging[current_index + 1][0]):\n",
        "            if(element.lexname() == current_type):\n",
        "                return True\n",
        "    return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9cf9ad5c",
      "metadata": {
        "id": "9cf9ad5c",
        "outputId": "abde0254-08d8-4ebb-db8b-2704c520cbee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n",
            "Warning: parsing empty text\n"
          ]
        }
      ],
      "source": [
        "# iterate all the sentences in the corpus; here, i = index and each_sentence = current element (sentence)\n",
        "for i, each_sentence in enumerate(Sentence):\n",
        "\n",
        "    # tokenize the sentences by using word_tokenizer() method of NLTK\n",
        "    words = nltk.word_tokenize(each_sentence)\n",
        "\n",
        "    # for loop to iterate all the tokens; here, j = index (integer) and each_word = current word\n",
        "    for j, each_word in enumerate(words):\n",
        "\n",
        "        # condition to check the presence of \"it\". By making sure that we convert it to lowercase\n",
        "        if(each_word.lower() == 'it'):\n",
        "            list_of_sentence.append(each_sentence)\n",
        "\n",
        "            # Feature 1 (Feature1): The position of “it” in the sentence considering the number of tokens.\n",
        "            Feature1.append(j + 1)\n",
        "\n",
        "            # Feature 2 (Feature2): The length of the sentence in terms of tokens.\n",
        "            Feature2.append(len(words))\n",
        "\n",
        "            # Feature 3 (Feature3): The number of punctuations.\n",
        "            # using pos_tag() method of nltk\n",
        "            pos_tagging = nltk.pos_tag(words)\n",
        "            punctuation_count = 0\n",
        "            for current_tag in pos_tagging:\n",
        "                # checking when we get a punctuation (can also be done by defining a list of punctuations)\n",
        "                if(current_tag[1] in string.punctuation):\n",
        "                    punctuation_count += 1\n",
        "            Feature3.append(punctuation_count)\n",
        "\n",
        "            # Feature 4 (Feature4): The number of preceding noun phrases.\n",
        "            # Base case\n",
        "            if(j!=0):\n",
        "                # using regexp parser for the Tree\n",
        "                pos_tagging = nltk.pos_tag(words[:j])\n",
        "                NP_tree_phrases = nltk.RegexpParser( \"NP: {<DT>?<JJ>*<NN>}\").parse(pos_tagging)\n",
        "                # calling check_noun_phrase() function (defined above)\n",
        "                Feature4.append(check_noun_phrase(NP_tree_phrases))\n",
        "            else:\n",
        "                Feature4.append(0)\n",
        "            # Feature 5 (Feature5): The number of noun phrases that follow a given instance of “it”.\n",
        "            # Base case when \"it\" is the last element\n",
        "            if(j==(len(words)-1)):\n",
        "                Feature5.append(0)\n",
        "            else:\n",
        "                pos_tagging = nltk.pos_tag(words[j+1:])\n",
        "                NP_tree = nltk.RegexpParser(\"NP: {<DT>?<JJ>*<NN>}\").parse(pos_tagging)\n",
        "                Feature5.append(check_noun_phrase(NP_tree))\n",
        "\n",
        "            # Feature 6 (Feature6): the pronoun “it” immediately follow a prepositional phrase.\n",
        "            pos_tagging = nltk.pos_tag(words[:j])\n",
        "            prepositional_phrase_tree = nltk.RegexpParser(\"PP: {<IN><PRP>}\").parse(pos_tagging)\n",
        "            flag = False\n",
        "            # the condition to check if \"it\" immediately follow a prepositional phrase\n",
        "            if(len(prepositional_phrase_tree) > 0 and type(prepositional_phrase_tree[len(prepositional_phrase_tree) - 1]) == nltk.tree.Tree and prepositional_phrase_tree[len(prepositional_phrase_tree) - 1].label() == 'PP'):\n",
        "                flag = True\n",
        "            Feature6.append(flag)\n",
        "\n",
        "            # Feature 7 (Feature7): The part-of-speech (POS) tags of the four tokens immediately preceding and the four tokens immediately succeeding a given instance of “it”.\n",
        "            pos_tagging = nltk.pos_tag(words)\n",
        "            answer_Feature7 = for_Feature7(j, pos_tagging)\n",
        "            Feature7_1.append(answer_Feature7[0])\n",
        "            Feature7_2.append(answer_Feature7[1])\n",
        "            Feature7_3.append(answer_Feature7[2])\n",
        "            Feature7_4.append(answer_Feature7[3])\n",
        "            Feature7_5.append(answer_Feature7[4])\n",
        "            Feature7_6.append(answer_Feature7[5])\n",
        "            Feature7_7.append(answer_Feature7[6])\n",
        "            Feature7_8.append(answer_Feature7[7])\n",
        "\n",
        "            # Feature 8 (Feature8): the occurrence of “it” followed by an -ing form of a verb\n",
        "            pos_tagging = nltk.pos_tag(words[j:])\n",
        "            Feature8.append(for_many('VBG', pos_tagging))\n",
        "\n",
        "            # Feature 9 (Feature9): the occurrence of “it” followed by a preposition\n",
        "            Feature9.append(for_many('IN', pos_tagging))\n",
        "\n",
        "            # Feature 10 (Feature10): The number of adjectives that follow the occurrence of “it” in the sentence\n",
        "            F10 = 0\n",
        "            for each_element in pos_tagging:\n",
        "                if(each_element[1]=='JJ'):\n",
        "                    F10+=1\n",
        "            Feature10.append(F10)\n",
        "\n",
        "            # Feature 11 (Feature11): the pronoun “it” preceded by a verb\n",
        "            pos_tagging = nltk.pos_tag(words[:j])\n",
        "            Feature11.append(for_verb(pos_tagging))\n",
        "\n",
        "            # Feature 12 (Feature12): the pronoun “it” followed by a verb\n",
        "            pos_tagging = nltk.pos_tag(words[j:])\n",
        "            Feature12.append(for_verb(pos_tagging))\n",
        "\n",
        "            # Feature 13 (Feature13): the pronoun “it” followed by an adjective\n",
        "            Feature13.append(for_many(\"JJ\", pos_tagging))\n",
        "\n",
        "            # Feature 14 (Feature14): a noun phrase coming after the pronoun “it” and that noun phrase contains an adjective\n",
        "            pos_tagging = nltk.pos_tag(words[j:])\n",
        "            NP_tree_for_Adjective = nltk.RegexpParser( \"NP: {<DT>?<JJ>*<NN>}\").parse(pos_tagging)\n",
        "            Feature14.append(for_NP_and_adjective(NP_tree_for_Adjective))\n",
        "\n",
        "            # Feature 15 (Feature15): number of tokens coming before the following infinitive verb\n",
        "            pos_tagging = nltk.pos_tag(words)\n",
        "            infinitive_verb_tree = nltk.RegexpParser(\"IV: {<TO><VB>}\").parse(pos_tagging)\n",
        "            count_infinitive_verb = 0\n",
        "            saw_IT = 0\n",
        "            saw_IV = 0\n",
        "            for element in infinitive_verb_tree:\n",
        "                count_infinitive_verb += 1\n",
        "                if(saw_IT == 1 and type(element) == nltk.tree.Tree and element.label() == 'IV'):\n",
        "                    saw_IV = 1\n",
        "                    break\n",
        "                if(type(element) != nltk.tree.Tree and element[0]==\"it\"):\n",
        "                    saw_IT = 1\n",
        "            if(saw_IV):\n",
        "                Feature15.append(count_infinitive_verb - 1)\n",
        "            else:\n",
        "                Feature15.append(0)\n",
        "\n",
        "            # Feature 16 (Feature16): number of tokens that appear between the pronoun “it” and the first following preposition\n",
        "            pos_tagging = nltk.pos_tag(words[j:])\n",
        "            count_tokens_PP = 0\n",
        "            found = 0\n",
        "            k = 0\n",
        "            while(k < len(pos_tagging)):\n",
        "                if(pos_tagging[k][1] == 'IN'):\n",
        "                    found = 1\n",
        "                    break\n",
        "                count_tokens_PP += 1\n",
        "                k += 1\n",
        "            if(found == 1):\n",
        "                Feature16.append(count_tokens_PP - 1)\n",
        "            else:\n",
        "                Feature16.append(0)\n",
        "\n",
        "\n",
        "            # Feature 18 (Feature18): dependency relation type with the closest word to which “it” is associated as a dependent.\n",
        "            depend_parser = spacy.load(\"en_core_web_sm\")\n",
        "            sentence = re.sub(\"\\s\\s+\" , \" \", each_sentence)\n",
        "            results = depend_parser(sentence)\n",
        "            Feature18.append(str(results[j].dep_))\n",
        "\n",
        "            # Feature 19 (Feature19): the immediately following verb belongs to the category “weather adjectives”\n",
        "            pos_tagging = nltk.pos_tag(words)\n",
        "            Feature19.append(wordnet_for_last_two(j, pos_tagging, len(words), \"verb.weather\"))\n",
        "\n",
        "            # Feature 20 (Feature20): the immediately following verb belongs to the category of cognitive verbs\n",
        "            Feature20.append(wordnet_for_last_two(j, pos_tagging, len(words), \"verb.cognition\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e40cec61",
      "metadata": {
        "id": "e40cec61"
      },
      "outputs": [],
      "source": [
        "# using dataframe for converting the output arrays into csv file.\n",
        "df = {}\n",
        "df['Sentences'] = list_of_sentence\n",
        "df['Feature1'] = Feature1\n",
        "df['Feature2'] = Feature2\n",
        "df['Feature3'] = Feature3\n",
        "df['Feature4'] = Feature4\n",
        "df['Feature5'] = Feature5\n",
        "df['Feature6'] = Feature6\n",
        "df['Feature7_1'] = Feature7_1\n",
        "df['Feature7_2'] = Feature7_2\n",
        "df['Feature7_3'] = Feature7_3\n",
        "df['Feature7_4'] = Feature7_4\n",
        "df['Feature7_5'] = Feature7_5\n",
        "df['Feature7_6'] = Feature7_6\n",
        "df['Feature7_7'] = Feature7_7\n",
        "df['Feature7_8'] = Feature7_8\n",
        "df['Feature8'] = Feature8\n",
        "df['Feature9'] = Feature9\n",
        "df['Feature10'] = Feature10\n",
        "df['Feature11'] = Feature11\n",
        "df['Feature12'] = Feature12\n",
        "df['Feature13'] = Feature13\n",
        "df['Feature14'] = Feature14\n",
        "df['Feature15'] = Feature15\n",
        "df['Feature16'] = Feature16\n",
        "df['Feature18'] = Feature18\n",
        "df['Feature19'] = Feature19\n",
        "df['Feature20'] = Feature20\n",
        "\n",
        "df = pd.DataFrame(df)\n",
        "df.to_csv(\"feature_data_solutions.csv\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}